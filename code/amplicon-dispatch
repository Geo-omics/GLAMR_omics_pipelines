#!/usr/bin/env python3
"""
Run DADA2 on amplicon sequences of given dataset to obtain ASVs and abundance
"""
import argparse
from collections import Counter
from pathlib import Path
from subprocess import CalledProcessError, run
import sys
from tempfile import TemporaryDirectory


GUESS_TARGET_SCRIPT = './guess-amplicon-target'
""" helper script, path relative to this script """

SUMMARIZE_HMMSCAN_SCRIPT = './summarize_hmmscan.R'
""" helper script, path relative to this script """


argp = argparse.ArgumentParser(description=__doc__)
argp.add_argument(
    'dataset',
    help='The dataset to process.',
)
argp.add_argument(
    '--test-mode',
    action='store_true',
    help='Run script in test mode.  In test mode...',
)
argp.add_argument(
    '--use-import-log',
    action='store_true',
    help='Get info on a dataset\'s samples from the import log.  This also '
    'checks that raw read files, etc. actually exist.  The default is to just '
    'look at the filesystem and does not check for file existence.  The '
    'snakemake run amplicon pipeline should use the default.',
)
argp.add_argument(
    '--outdir',
    default='./',
    help='Output directory.  Defaults to the current working directory.'
)
argp.add_argument(
    '--data-root',
    default='data/',
    help='Path to the data directory.  Defaults to ./data',
)
args = argp.parse_args()


root = Path(args.data_root)
if not root.is_dir():
    argp.error(f'not a directory: {root}')


def get_sample_info_log():
    """ collect info from omics pipeline import log """
    try:
        import_log = \
            sorted((root / 'import_logs').glob('*_sample_status.tsv'))[-1]
    except Exception as e:
        argp.error(f'Failed finding import log: {e.__class__.__name__}: {e}')

    data = []
    with open(import_log) as ifile:
        print(f'Reading import log: {import_log}... ', end='', flush=True)
        header = ifile.readline().strip().split('\t')
        for line in ifile:
            row = dict(zip(header, line.strip().split('\t')))

            if not row['StudyID'] == args.dataset:
                continue

            if not row['sample_type'] == 'amplicon':
                continue

            if not row['import_success'] == 'TRUE':
                continue

            # check sample dir
            try:
                sample_dir = root / Path(row['sample_dir']).relative_to('data')
            except ValueError as e:
                argp.error(f'failed parsing sample_dir: {e}\n{row=}')

            # get paths to fastq files
            fwd = Path(row['raw_reads_fp'])
            try:
                fwd = root / fwd.relative_to('data')
            except ValueError as e:
                argp.error(f'unexpected path: {e}\n{row=}')

            if not fwd.is_file():
                argp.error(f'forward fastq file does not exist: {fwd}')

            rev = fwd.parent / (fwd.name.replace('fwd', 'rev'))
            if not rev.is_file():
                argp.error(f'reverse fastq file does not exist: {rev}')

            data.append({
                'sample_id': row['SampleID'],
                'sample_dir': sample_dir,
                'fwd_fastq': fwd,
                'rev_fastq': rev,
            })
    print('[OK]')

    return data


def get_sample_info():
    """ get sample info from filesystem """
    base = root / 'projects' / args.dataset / 'amplicons'
    absroot = root.resolve()
    if not base.is_dir():
        argp.error(f'no such directory: {base}')
    data = []
    for sampdir in base.glob('samp_*'):
        sampdir = sampdir.resolve().relative_to(absroot.parent)
        data.append({
            'sample_id': sampdir.name,
            'sample_dir': sampdir,
            'fwd_fastq': sampdir / 'reads' / 'raw_fwd_reads.fastq.gz',
            'rev_fastq': sampdir / 'reads' / 'raw_rev_reads.fastq.gz',
        })
    return data


def get_target_info(data):
    """ detect amplicon target genes and regions """

    for sample_info in data:
        sample_id = sample_info['sample_id']
        detect_region_dir = sample_info['sample_dir'] / 'detect_region'
        if not detect_region_dir.is_dir():
            print(f'{sample_id}: not a directory: {detect_region_dir=}')
            continue

        if args.test_mode:
            # in test mode generate target info from nhmmscan output
            tmpd = None
            script_dir = Path(__file__).resolve().parent
            try:
                sum_fwd = detect_region_dir / 'fwd_summary.tsv'
                sum_rev = detect_region_dir / 'rev_summary.tsv'

                if not sum_fwd.is_file or not sum_rev.is_file():
                    tmpd = TemporaryDirectory()
                    tmp = Path(tmpd.name)
                    hmm_fwd = detect_region_dir / 'fwd.txt'
                    hmm_rev = detect_region_dir / 'rev.txt'
                    sum_fwd = tmp / 'fwd_summary.tsv'
                    sum_rev = tmp / 'rev_summary.tsv'
                    sum_script = script_dir / SUMMARIZE_HMMSCAN_SCRIPT
                    run(
                        [sum_script, '--input', hmm_fwd, '--output', sum_fwd],
                        capture_output=True,
                        check=True,
                        cwd=tmp,
                    )
                    run(
                        [sum_script, '--input', hmm_rev, '--output', sum_fwd],
                        capture_output=True,
                        check=True,
                        cwd=tmp,
                    )

                guess_script = script_dir / GUESS_TARGET_SCRIPT
                proc = run(
                    [guess_script, str(sum_fwd), str(sum_rev)],
                    capture_output=True,
                    check=True,
                    cwd=tmp if tmpd else None,
                )
            except CalledProcessError as e:
                print(e.stderr.decode(), file=sys.stderr)
                argp.error(f'ERROR calling {e}')
            finally:
                if tmpd:
                    tmpd.cleanup()

            info_txt = proc.stdout.decode()
        else:
            info_txt = (detect_region_dir / 'target_info.txt').read_text()

        try:
            header, row, *errors = info_txt.splitlines()
        except Exception as e:
            argp.error(f'expected two lines of stdout from {proc}: {e}')

        target_data = dict(zip(
            header.rstrip('\n').split('\t'),
            row.rstrip('\n').split('\t'),
            strict=True,
        ))
        cols = ['tax_group', 'gene', 'regions', 'dirs_swapped', 'got_error']
        for key in cols:
            sample_info[key] = target_data[key]


def find_mode(data):
    TARGET_KEYS = ('tax_group', 'gene', 'regions')
    targets = Counter((
        tuple((i[k] for k in TARGET_KEYS))
        for i in data
    )).most_common()

    winner, winner_count = targets[0]

    for trgt, count in targets:
        print(f'{count:>4} x {" // ".join(trgt)}')

    if winner_count <= len(data) / 2:
        argp.error('there is no clear target !!!')

    if bad_count := len(data) - winner_count:
        print(f'Discarding {bad_count} samples with bad amplicon targets.')

    # return only good sample's info
    return winner, [
        i for i in data
        if tuple((i[k] for k in TARGET_KEYS)) == winner
    ]


def dispatch(winner, data):
    """
    List the samples to be analyzed together in one dada2 run
    """
    tax_group, gene, regions = winner
    target_str = f'{tax_group}-{gene}-{regions.replace(",", "-")}'

    final_outdir = Path(args.outdir)
    if keep_outdir := final_outdir.is_dir():
        outdir = final_outdir
    else:
        tmpd = TemporaryDirectory(
            prefix=final_outdir.name + '.tmp.',
            dir=final_outdir.parent,
            delete=False,
        )
        outdir = Path(tmpd.name)

    columns = [
        'sample_id', 'sample_dir', 'dirs_swapped', 'fwd_fastq', 'rev_fastq',
    ]
    outfile = outdir / f'sample_info.{target_str}'
    with outfile.open('w') as ofile:
        for row in data:
            ofile.write('\t'.join(str(row[i]) for i in columns))
            ofile.write('\n')
    print(f'{len(data)} records written to {outfile}')
    if not keep_outdir:
        outdir.rename(final_outdir)


# MAIN
data = get_sample_info_log() if args.use_import_log else get_sample_info()
if data:
    print(f'Found info on {len(data)} samples')
else:
    argp.error('No samples found')
print('Guessing amplicon targets... ', end='', flush=True)
get_target_info(data)
print('[OK]')
winner, data = find_mode(data)
if not args.test_mode:
    dispatch(winner, data)
