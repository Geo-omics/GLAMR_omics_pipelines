# Get import sample names
#metaG_samples = glob_wildcards("import/metagenomes/{sample}/").sample
#metaT_samples = glob_wildcards("import/metatranscriptomes/{sample}/").sample
#metabolome_samples = glob_wildcards("import/metabolomes/{sample}/").sample
#amplicon_samples = glob_wildcards("import/amplicons/{sample}/").sample


# Get sample names
start_time = time.time() # for testing how long it takes to parse out names

metaG_samples = open("data/sample_metadata/sample_lists/metaG_samples").read().splitlines()
all_metaG_samples = open("data/sample_metadata/sample_lists/all_metaG_samples").read().splitlines()
assembled_samples = open("data/sample_metadata/sample_lists/assembled_samples").read().splitlines()
qcd_samples = open("data/sample_metadata/sample_lists/qcd_samples").read().splitlines()
qcd_transcript_samples = open("data/sample_metadata/sample_lists/qcd_transcript_samples").read().splitlines()
jgi_samples = open("data/sample_metadata/sample_lists/jgi_samples").read().splitlines()
glerl_samples = open("data/sample_metadata/sample_lists/glerl_samples").read().splitlines()
transect_samples = open("data/sample_metadata/sample_lists/transect_samples").read().splitlines()
quast_samples = open("data/sample_metadata/sample_lists/quast_samples").read().splitlines()
read_download_samples = open("data/sample_metadata/sample_lists/read_download_samples").read().splitlines()
read_download_transcript_samples = open("data/sample_metadata/sample_lists/read_download_transcript_samples").read().splitlines()
read_download_amplicon_samples = open("data/sample_metadata/sample_lists/read_download_amplicon_samples").read().splitlines()
metaT_samples = open("data/sample_metadata/sample_lists/metaT_samples").read().splitlines()
metabolome_samples = open("data/sample_metadata/sample_lists/metabolome_samples").read().splitlines()
amplicon_samples = open("data/sample_metadata/sample_lists/amplicon_samples").read().splitlines()
seagull_samples = open("data/sample_metadata/size_sorted_HABs_samples_Seagull.tsv").read().splitlines()
victoria2022_samples = open("data/sample_metadata/sample_lists/victoria2022_samples").read().splitlines()
kenya2023_samples = open("data/sample_metadata/sample_lists/kenya2023_samples").read().splitlines()

rule blast_Didymosphenia_geminata_chloroplast_16S:
    input:
        expand("data/omics/metagenomes/{sample}/BLAST/Didymosphenia_geminata_chloroplast_16S__{sample}.blastn", sample=metaG_samples)

# Old items
#metaG_samples = glob_wildcards("data/projects/2022_geomicro_JGI_CSP/metagenomes/{sample}/reads/decon_fwd_reads_fastp.fastq.gz", followlinks=True).sample
#metaG_samples = os.popen("ls data/projects/PRJNA702522/metagenomes/").read().splitlines() #+ os.popen("ls data/projects/PRJNA679730/metagenomes/").read().splitlines() #ESP 2018 & 19
#metaG_samples = os.popen("ls data/projects/PRJNA702522/metagenomes/").read().splitlines() #ESP1
#metaG_samples = os.popen("ls data/projects/2021_ESP/metagenomes/").read().splitlines() #ESP 2021
#metaG_samples =  os.popen("ls data/projects/GLERL_USGS_2016_2020/metagenomes/").read().splitlines() + os.popen("ls data/projects/WLE_transects_2022/metagenomes/").read().splitlines()
#metaG_samples = glob_wildcards("data/projects/2022_geomicro_JGI_CSP/metagenomes/{sample}/").sample
#metaG_samples = glob_wildcards("data/projects/PRJNA464361/metagenomes/{sample}/").sample
#metaG_samples = ["E20212019","E20212012","E20212013","E20212010"]

end_time = time.time() # Record end of name parsing
execution_time = end_time - start_time
#print(f"Name processing time: {execution_time} seconds")


# rule import:
#     input:
#     output:
#     resources: cpus=1, mem_mb=8000, time_min=2880, mem_gb = 8
#     shell:
#         """

#         """

# rule gzip_fastx:

# rule unzip_fastx:


# rule zip_fastqs:
#     input:  SCRATCH + "/01RAW_fqs/{sample}"
#     output: temp(SCRATCH + "/02ZIPPED_fqs/{sample}")
#     params: outdir = SCRATCH + "/02ZIPPED_fqs/"
#     run:

#         if wildcards.sample.endswith('.fastq'):
#             shell("echo gzip {input}")
#             shell("echo mv {input}.gz {params.outdir}")
#         else:
#             shell("mv {input} {params.outdir}")


# Target rules

rule run_get_reads:
    input:
        expand("data/omics/metagenomes/{sample}/reads/raw_fwd_reads.fastq.gz", sample = read_download_samples),
        expand("data/omics/metatranscriptomes/{sample}/reads/raw_fwd_reads.fastq.gz", sample = read_download_transcript_samples),
        expand("data/omics/amplicons/{sample}/reads/raw_fwd_reads.fastq.gz", sample = read_download_amplicon_samples)


rule assemble:
    input: 
        #expand("data/omics/metagenomes/{sample}/assembly/metaspades/contigs.fasta",sample = metaG_samples),
        #expand("data/omics/metagenomes/{sample}/assembly/megahit/final.contigs.fa",sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/assembly/metaspades_noNORM/contigs.fasta",sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa",sample = metaG_samples)

rule run_megahit:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa", sample = all_metaG_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = all_metaG_samples)

rule run_quast:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = quast_samples)

rule run_metaspades:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/metaspades_noNORM/contigs.fasta",sample = metaG_samples)

rule run_biosyntheticSPAdes:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/biosyntheticSPAdes/scaffolds.fasta", sample = jgi_samples)

rule run_prodigal:
    input: expand("data/omics/metagenomes/{sample}/proteins/{sample}_PROTEINS.faa", sample = metaG_samples)

rule test:
    input: expand("data/omics/metagenomes/{sample}/reads/raw_fwd_reads.fastq.gz",sample = metaG_samples)
    output: "test.out"

rule lauren_assembly_and_BGC_test:
    input:
        # Assemblies
        expand("data/omics/metagenomes/{sample}/assembly/metaspades/contigs.fasta",sample = glerl_samples + jgi_samples + transect_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit/final.contigs.fa",sample = glerl_samples + jgi_samples + transect_samples),
        expand("data/omics/metagenomes/{sample}/assembly/metaspades_noNORM/contigs.fasta",sample = glerl_samples + jgi_samples + transect_samples),
        #expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa",sample = glerl_samples + jgi_samples + transect_samples),
        expand("data/omics/metagenomes/{sample}/assembly/biosyntheticSPAdes/scaffolds.fasta", sample = glerl_samples + jgi_samples + transect_samples),
        expand("data/omics/metagenomes/{sample}/assembly/biosyntheticSPAdes_100x/scaffolds.fasta", sample = glerl_samples + jgi_samples + transect_samples)

rule assemble_victoria:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa", sample = victoria2022_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = victoria2022_samples)


rule assemble_kenya23:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa", sample = kenya2023_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = kenya2023_samples),
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample=kenya2023_samples)

rule assemble_glerl2:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa", sample = glerl_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = glerl_samples),
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample=glerl_samples)

rule assemble_victoria_spades:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/metaspades_noNORM/contigs.fasta",sample = victoria2022_samples)

hegarty_samples = ["samp_4457","samp_4458"]
rule hegarty_check:
    input:
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa", sample = hegarty_samples),
        expand("data/omics/metagenomes/{sample}/assembly/megahit_noNORM/quast/report.tsv", sample = hegarty_samples),
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample= hegarty_samples)


rule run_fastqc_decontam:
    input: expand("data/omics/metagenomes/{sample}/reads/fastqc_decontam/.done", sample = metaG_samples)

    rule run_count_reads:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count.tsv", sample=metaG_samples),
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample=metaG_samples)

rule run_count_reads_fastp:
    input:
        expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample=qcd_samples)

rule run_multi_quast:
    input: expand("data/omics/metagenomes/{sample}/assembly/quast", sample = metaG_samples)

rule calc_contig_abund:
    input: expand("data/omics/metagenomes/{sample}/{sample}_contig_abund.tsv", sample = assembled_samples)


    rule make_uniref_alignments:
    input: 
        expand("data/omics/metagenomes/{sample}/{sample}_GENES.m8",sample = list(filter(lambda x: x.startswith('samp_'), qcd_samples))),
        expand("data/omics/metagenomes/{sample}/genes/{sample}_READSvsGENES.rpkm",sample = list(filter(lambda x: x.startswith('samp_'), qcd_samples)))

# Required input for the annotation script: 
# print "\t1. The gene or protein sequences:                      [sample]_GENES.fna\n";
# print "\t2. The alignment file of the sequences to UMRAD:       [sample]_GENES.m8 \n";
# print "\t3. The rpkm file for reads aligned to the genes:       [sample]_READSvsGENES.rpkm\n";
# print "\t4. The rpkm file for reads aligned to the contigs:     [sample]_READSvsCONTIGS.rpkm\n";
# print "\t5. The sample contigs sequences:                       [sample]_MCDD.fa\n\n";


#             /TAXONOMY\_DB.*$year\.txt/){	$intax	=$refdir.$file;}
# if($file =~ /UNIREF100\_INFO.*$year\.txt/){	$ininfo	=$refdir.$file;}
# if($file =~ /Function\_Names.*\.txt/){	


# Target rules for running kraken
rule calc_kraken_uniq:
    input: expand("data/omics/metagenomes/{sample}/kraken/{database}_{sample}_out.txt", database = ["refseq","gtdb_r202"], sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/kraken/{database}_{sample}_brackenMpa.txt", database = ["refseq","gtdb_r202"], sample = metaG_samples)

rule calc_kraken_uniq_gtdb:
    input: expand("data/omics/metagenomes/{sample}/kraken/{database}_{sample}_brackenMpa.txt", database = ["gtdb_r202"], sample = metaG_samples)


# Target rule to make all the metacodeR plots
rule plot_metacoders:
    input: expand("data/omics/metagenomes/{sample}/kraken/{sample}_kraken_metacodeR.pdf", sample=metaG_samples)


rule run_humann: 
    input: expand("data/omics/metagenomes/{sample}/humann", sample=metaG_samples)

rule run_humann_fastp: 
    input: expand("data/omics/metagenomes/{sample}/humann_fastp", sample=metaG_samples)


# Depricated, remove
# rule metacodeR:
#     input:
#         script = "code/plot_metacoder.R",
#         abund = "data/sample_data/bracken_rel_abund.tsv"
#         #metadata = "data/metadata.tsv"
#     output: "data/omics/{sample_type}/{sample}/kraken/{sample}_kraken_metacodeR.pdf"
#     resources: cpus=1, mem_mb=8000, time_min=60
#     container: "docker://eandersk/r_microbiome"
#     shell:
#         """
#         {input.script} --abund={input.abund} --sample={wildcards.sample} --output={output}
#         """

# Combine the kraken annotations and produce count table
# rule kraken_summarize_fastp:
#     input:
#         script = "code/merge_bracken.R",
#         kraken_results = expand("data/omics/{sample_type}/{sample}/kraken_fastp/{database}_{sample}_bracken.txt", database = ["refseq","gtdb"], sample = metaG_samples, sample_type = "metagenomes"),
#         combined_tax_info = rules.kraken_database_tax_merge.output.combined_tax_info
#     output:
#         counts = "data/sample_data/bracken_counts.tsv",
#         rel_abund = "data/sample_data/bracken_rel_abund.tsv"
#     resources: cpus=1, mem_mb=5000, time_min=60
#     container: "docker://eandersk/r_microbiome"
#     shell:
#         """
#         ./{input.script} --taxonomy={input.combined_tax_info} --counts-out={output.counts} --rel-out={output.rel_abund}
#         """

################


# rule assemble_megahit:
#     input:
#         fwd_reads = rules.bbnorm.output.fwd_norm,
#         rev_reads = rules.bbnorm.output.rev_norm
#     output:
#         touch("data/omics/metagenomes/{sample}/assembly/megahit/.done")
#     params:
#         assembly_dir = directory("data/omics/metagenomes/{sample}/assembly/megahit")
#     conda: "config/conda_yaml/main.yaml"
#     log: "logs/assembly/megahit/{sample}.log"
#     benchmark: "benchmarks/megahit/{sample}.txt"
#     resources: cpus = 16, time_min=7200, mem_mb = lambda wildcards, attempt: attempt * 100000
#     shell:
#         """
#         rm -r {params.assembly_dir} # for re-running, megahit doesn't overwrite automatically
#         megahit -t {resources.cpus} --presets meta-sensitive -m 0.5 -1 {input.fwd_reads} -2 {input.rev_reads} -o {params.assembly_dir} 2>&1 | tee {log}
#         """

# rule rename_megahit_contigs:
#     input: 
#         script = "code/rename_megahit_contigs.R",
#         assembly_dir = "data/omics/metagenomes/{sample}/assembly/megahit",
#         megahit_done = "data/omics/metagenomes/{sample}/assembly/megahit/.done"
#     output:
#         contigs = "data/omics/metagenomes/{sample}/assembly/megahit/final.contigs.fa",
#         done = touch("data/omics/metagenomes/{sample}/assembly/megahit/.contigs_renamed")
#     container: "docker://eandersk/r_microbiome"
#     resources: cpus = 1, time_min=200, mem_mb = 20000
#     shell:
#         """
#         pwd
#         ./{input.script} {output.contigs}
#         """


# rule rename_megahit_contigs:
#     input: 
#         script = "code/rename_contigs.R",
#         #assembly_dir = "data/omics/metagenomes/{sample}/assembly/megahit",
#         contigs = "data/projects/{project}/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.fa",
#         #assembly_done = "data/omics/metagenomes/{sample}/assembly/megahit/.done"
#     output:
#         contigs = "data/projects/{project}/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.renamed.fa",
#         contig_info = "data/projects/{project}/metagenomes/{sample}/assembly/megahit_noNORM/contigs_info.tsv"
#         #done = touch("data/omics/metagenomes/{sample}/assembly/megahit/.contigs_renamed")
#     container: "docker://eandersk/r_microbiome"
#     resources: cpus = 1, time_min=200, mem_mb = 50000
#     shell:
#         """
#         pwd
        
#         ./{input.script} \
#             -i {input.contigs} \
#             -o {output.contigs} \
#             -s {output.contig_info} \
#             -p {wildcards.sample}
#         """

rule run_mmseqsLCA_GL:
    input: 
        #expand("data/omics/metagenomes/{sample}/{sample}_report", sample = seagull_samples),
        #expand("data/omics/metagenomes/{sample}/{sample}_report_w_full_lineage", sample = seagull_samples),
        # expand("data/omics/metagenomes/{sample}/{sample}_report", sample = qcd_samples),
        # expand("data/omics/metagenomes/{sample}/{sample}_report_w_full_lineage", sample = qcd_samples)
        expand("data/omics/metagenomes/{sample}/{sample}_report", sample = glerl_samples),
        expand("data/omics/metagenomes/{sample}/{sample}_report_w_full_lineage", sample = glerl_samples)


rule run_mmseqsLCA_contig_largemem:
    input: 
        expand("data/omics/metagenomes/{sample}/{sample}_contig_report", sample = seagull_samples),
        expand("data/omics/metagenomes/{sample}/{sample}_lca_abund_summarized.tsv", sample=seagull_samples),
        expand("data/omics/metagenomes/{sample}/{sample}_contig_abund.tsv", sample = seagull_samples)


# rule reads_unirefLCA_mmseqs_geomicro:
#     input:
#         fwd_reads = "data/omics/metagenomes/{sample}/reads/decon_fwd_reads_fastp.fastq.gz",
#         rev_reads = "data/omics/metagenomes/{sample}/reads/decon_rev_reads_fastp.fastq.gz"
#     output:
#         report = "data/omics/metagenomes/{sample}/{sample}_report"
#     conda:  "config/conda_yaml/mmseqs.yaml"
#     params:
#         unirefDB = "data/reference/mmseqs2/uniref100",
#         out_prefix = "data/omics/metagenomes/{sample}/{sample}",
#         tmp_dir = "/tmp",
#         tmp_fwd_reads = "/home/kiledal/scratch_gdick1/mmseqs/{sample}/{sample}__fwd.fastq.gz",
#         tmp_rev_reads = "/home/kiledal/scratch_gdick1/mmseqs/{sample}/{sample}__rev.fastq.gz",
#     benchmark: "benchmarks/reads_unirefLCA_mmseqs_geomicro/{sample}.txt"
#     log: "logs/reads_unirefLCA_mmseqs_geomicro/{sample}.log"
#     resources:
#         mem_mb = 750000, cpus=48, time_min=20000
#     shell:
#         """
#         #mkdir -p {params.tmp_dir}

#         #cp {input.fwd_reads} {params.tmp_fwd_reads}
#         #cp {input.rev_reads} {params.tmp_rev_reads} 

#         mmseqs touchdb {params.unirefDB}
        
#         mmseqs \
#             easy-taxonomy \
#             {input.fwd_reads} {input.rev_reads} \
#             {params.unirefDB} \
#             ./{params.out_prefix} \
#             {params.tmp_dir} \
#             --lca-mode 3 \
#             -s 4 \
#             --tax-lineage 1 \
#             --threads {resources.cpus} \
#             --db-load-mode 2
#             #--split-memory-limit 150G

#         rm -r {params.tmp_fwd_reads} {params.tmp_rev_reads} {params.tmp_dir}
#         """

# rule run_mmseqsLCA_geo:
#     input: expand("data/omics/metagenomes/{sample}/{sample}_report", sample = qcd_samples)


rule run_kofam_scan:
    input:
        expand("data/omics/metagenomes/{sample}/kofam_scan/{sample}_kofam_results.txt", sample = metaG_samples)

        rule metaG_annotation:
        input: 
            #expand("data/omics/metagenomes/{sample}/annotation", sample = metaG_samples),
            expand("data/omics/metagenomes/{sample}/.annotation_done", sample = metaG_samples),
            expand("data/omics/metagenomes/{sample}/reads/{sample}_read_count_fastp.tsv", sample = metaG_samples)
            #expand("data/omics/metagenomes/{sample}/bins/metabat2_bins", sample = metaG_samples),
            #expand("data/omics/metagenomes/{sample}/bins/gtdbtk", sample = metaG_samples),
            #expand("data/omics/metagenomes/{sample}/bins/checkm.txt", sample = metaG_samples)
    
    
# rule initial_binning:
#     input:
#     output:
#     conda: "config/conda_yaml/main.yaml"
#     resources: 
#     shell:
#         """
#        while read i; do echo "doing $i"; 
#             #metabat
#             awk -F'\t' '{print $1"\t"$2"\t"$6"\t"$6"\t"$6"\t"}' ${i}_READSvsCONTIGS.rpkm > ${i}_MB_abund.txt
#             metabat2 --maxP=97 --minS=93 --maxEdges=300 -m 1500 -i ${i}_MERGED_CONTIGS_COR.fasta -a ${i}_MB_abund.txt -o ${i}_MB_bins
#             metabat2 --maxP=99 --minS=97 --maxEdges=300 -m 1500 -i ${i}_MERGED_CONTIGS_COR.fasta -a ${i}_MB_abund.txt -o ${i}_MB_bins
#             #maxbin
#             awk -F'\t' '{print $1"\t"$6}' ${i}_READSvsCONTIGS.rpkm | grep "CLUSTER" > ${i}_MX_abund.txt
#             perl run_MaxBin.pl -thread 20 -contig ${i}_MERGED_CONTIGS_COR.fasta -abund ${i}_MX_abund.txt -out ${i}_MX_bins
#         done < samp_list.txt;
#         """
    
    
    
rule make_bins:
    input:
        #contigs = rules.MEC.output.corrected_assembly,
        contigs = rules.rename_contigs.output.contigs,
        fwd_reads = rules.remove_contaminants.output.decon_fwd,
        rev_reads = rules.remove_contaminants.output.decon_rev
    output:
        directory("data/omics/{sample_type}/{sample}/bins/concoct_bins"),
        directory("data/omics/{sample_type}/{sample}/bins/maxbin2_bins"),
        directory("data/omics/{sample_type}/{sample}/bins/metabat2_bins"),
        directory("data/omics/{sample_type}/{sample}/bins/work_files"),
        "data/omics/{sample_type}/{sample}/bins/work_files/assembly.fa",
        fwd_reads = temp("data/omics/{sample_type}/{sample}/reads/reads_1.fastq"),
        rev_reads = temp("data/omics/{sample_type}/{sample}/reads/reads_2.fastq"),
        #out_dir = directory("data/omics/{sample_type}/{sample}/bins")
    params:
        out_dir = "data/omics/{sample_type}/{sample}/bins"
    conda: "config/conda_yaml/metawrap.yaml"
    resources: cpus=16, mem_mb=50000, time_min=2880, mem_gb = 50
    shell:
        """
        WORK_DIR=$PWD

        #data/omics/{wildcards.sample_type}/{wildcards.sample}/bins
        #mkdir -p data/omics/{wildcards.sample_type}/{wildcards.sample}/bins
        #cp data/qc_sequence_files/{wildcards.sample}[a-z]_R[12].fastq.gz data/bins/{wildcards.sample}/metaspades/
        gunzip -c {input.fwd_reads} > {output.fwd_reads}
        gunzip -c {input.rev_reads} > {output.rev_reads}
    
        #cd data/bins/{wildcards.sample}/metaspades
        #rename _R1.fastq _1.fastq *_R1.fastq
        #rename _R2.fastq _2.fastq *_R2.fastq

        #cd $WORK_DIR

        metawrap binning \
            -a {input.contigs} \
            -o {params.out_dir} \
            -t {resources.cpus} \
            -m {resources.mem_gb} \
            --metabat2 \
            --maxbin2 \
            --concoct \
            --universal \
            {output.fwd_reads} \
            {output.rev_reads}

        #rm -f data/bins/{wildcards.sample}/metaspades/*.fastq
        """


rule checkm:
    input: rules.dastool.output.das_bins_folder
    output:
        dir = temp(directory("data/omics/{sample_type}/{sample}/bins/checkm")),
        results = "data/omics/{sample_type}/{sample}/bins/checkm.txt"
    conda: "config/conda_yaml/checkm.yaml"
    resources: cpus=8, mem_mb=80000, time_min=2880, mem_gb = 80
    shell:
        """
        checkm lineage_wf --tab_table -f {output.results} -x fa -t {resources.cpus} {input} {output.dir}
        """

rule dastool:
    input:
        contigs = "data/omics/{sample_type}/{sample}/bins/work_files/assembly.fa",
        #bin_folder = rules.make_bins.params.out_dir
        bins = "data/omics/{sample_type}/{sample}/bins/metabat2_bins"
    params:
        bin_folder = rules.make_bins.params.out_dir
    output: 
        #summary = "data/omics/{sample_type}/{sample}/bins/DASTool/_DASTool_summary.txt",
        das_folder = directory("data/omics/{sample_type}/{sample}/bins/DASTool"),
        das_bins_folder = directory("data/omics/{sample_type}/{sample}/bins/DASTool/_DASTool_bins")
    conda: "config/conda_yaml/das_tool.yaml"
    resources: cpus=8, mem_mb=50000, time_min=2880, mem_gb = 50
    shell:
        """
        touch {params.bin_folder}/ran_dastool.touch # for tracking that DAStool ran, even if unsuccessfully

        #Maxbin2
        Fasta_to_Contig2Bin.sh \
        -i {params.bin_folder}/maxbin2_bins \
        -e fa \
        > {params.bin_folder}/maxbin.scaffolds2bin.tsv

        #CONCOT
        Fasta_to_Contig2Bin.sh \
        -i {params.bin_folder}/concoct_bins \
        -e fa \
        > {params.bin_folder}/concoct.scaffolds2bin.tsv

        #Metabat2
        Fasta_to_Contig2Bin.sh \
        -i {params.bin_folder}/metabat2_bins \
        -e fa \
        > {params.bin_folder}/metabat2.scaffolds2bin.tsv

        DAS_Tool \
            -i {params.bin_folder}/maxbin.scaffolds2bin.tsv,{params.bin_folder}/concoct.scaffolds2bin.tsv,{params.bin_folder}/metabat2.scaffolds2bin.tsv \
            -l maxbin,concoct,metabat2 \
            -c {input.contigs} \
            -t {resources.cpus} \
            --write_bins \
            -o {output.das_folder}/

        # Rename bins to include sample name, make several downstream analyses easier
        cd {output.das_bins_folder}
        for f in *.fa; do mv -v -- "$f" "{wildcards.sample}_$f"; done
        """

rule das_mag_coverage:
    input:
        fwd_reads = rules.remove_contaminants_fastp.output.decon_fwd,
        rev_reads = rules.remove_contaminants_fastp.output.decon_rev,
        bins = rules.dastool.output.das_bins_folder
    output: "data/omics/{sample_type}/{sample}/bins/coverage_das_bins.tsv"
    conda: "config/conda_yaml/coverm_env.yaml"
    resources: cpus=24, mem_mb=150000, time_min=2880
    shell:
        """
        [[ "${{HOSTNAME}}" == "cayman" || "${{HOSTNAME}}" == "vondamm" ]] && export TMPDIR=/scratch/$USER/
        
        coverm genome \
            -t {resources.cpus} \
            -m relative_abundance mean trimmed_mean covered_bases variance length count reads_per_base rpkm tpm \
            --min-covered-fraction 0 \
            --output-format sparse \
            -1 {input.fwd_reads} \
            -2 {input.rev_reads} \
            --genome-fasta-files {input.bins}/*.fa \
            -o {output}
        """

rule map_to_bins_for_reassembly:
    input:
        fwd_reads = rules.remove_contaminants.output.cleaned_fwd,
        rev_reads = rules.remove_contaminants.output.cleaned_rev,
        bins_folder = rules.dastool.output.das_bins_folder,
        bin = "data/omics/{sample_type}/{sample}/bins/DASTool/_DASTool_bins/{bin}.fa"
    output:
        #unfiltered_bam = "data/omics/{sample_type}/{sample}/bins/reassembly/reads/{bin}_prefilt.bam",
        unfiltered_bam_dir = temp(directory("data/omics/{sample_type}/{sample}/bins/reassembly/mapped_reads/{bin}__bam_unfiltered")),
        filtered_bam = temp("data/omics/{sample_type}/{sample}/bins/reassembly/mapped_reads/{bin}.bam"),
        #filtered_bam_dir = directory("data/omics/{sample_type}/{sample}/bins/reassembly/reads/{bin}__bam_filtered"),
        fwd_reads = temp("data/omics/{sample_type}/{sample}/bins/reassembly/mapped_reads/{bin}_R1.fastq.gz"),
        rev_reads = temp("data/omics/{sample_type}/{sample}/bins/reassembly/mapped_reads/{bin}_R2.fastq.gz")
    conda: "config/conda_yaml/coverm.yaml"
    resources: cpus=24, mem_mb=100000, time_min=2880
    shell:
        """
        coverm make \
            -t {resources.cpus} \
            -1 {input.fwd_reads} \
            -2 {input.rev_reads} \
            --reference {input.bin} \
            -o {output.unfiltered_bam_dir}

        coverm filter \
            -b {output.unfiltered_bam_dir}/*.bam \
            -o {output.filtered_bam} \
            --min-read-percent-identity 0.98 \
            --threads {resources.cpus}

        samtools fastq -@ {resources.cpus} \
            {output.filtered_bam} \
            -1 {output.fwd_reads} \
            -2 {output.rev_reads} \
            -0 /dev/null -s /dev/null -n
        """

rule reassemble_bin:
    input:
        fwd_reads = rules.map_to_bins_for_reassembly.output.fwd_reads,
        rev_reads = rules.map_to_bins_for_reassembly.output.rev_reads,
        bin = "data/omics/{sample_type}/{sample}/bins/DASTool/_DASTool_bins/{bin}.fa"
    output:
        #assembly_dir = directory("data/omics/{sample_type}/{sample}/bins/reassembly/{bin}"),
        contigs = "data/omics/{sample_type}/{sample}/bins/reassembly/{bin}_reassembled_contigs.fasta"
    params: 
        assembly_dir = directory("data/omics/{sample_type}/{sample}/bins/reassembly/{bin}")
    conda: "config/conda_yaml/main.yaml"
    log: "logs/bin_reassembly/{sample_type}-{sample}/{bin}.log"
    benchmark: "logs/bin_reassembly/{sample_type}-{sample}/{bin}.log"
    resources: cpus = 16, time_min=20160, mem_mb = 16000
        #mem_mb = lambda wildcards, attempt: attempt * 100000
    shell:
        """
        spades.py \
            -t {resources.cpus} \
            -m $(echo "scale=-1; ({resources.mem_mb}/1000)/1" | bc) \
            --careful \
		    --untrusted-contigs {input.bin} \
		    -1 {input.fwd_reads} \
		    -2 {input.rev_reads} \
		    -o {params.assembly_dir} > {log}

        mv {params.assembly_dir}/contigs.fasta {output.contigs}
        rm -r {params.assembly_dir}
        """

checkpoint drep:
    input: 
        bins = rules.gather_bin.output
    output:
        main_dir = directory("data/omics/metagenome_bins/derep"),
        MAGs= directory("data/omics/metagenome_bins/derep/dereplicated_genomes")
    conda: "config/conda_yaml/drep.yaml"
    resources: cpus=8, mem_mb=250000, time_min=2880,
    shell:
        """
        dRep dereplicate {output.main_dir} -g {input.bins}/*.fa
        """


rule gather_bin:
    input: expand("data/omics/{sample_type}/{sample}/bins/ran_dastool.touch",sample=metaG_samples,sample_type ="metagenomes")
    output: directory("data/omics/metagenome_bins")
    shell:
        """
        mkdir -p {output}
        
        ln data/omics/{wildcards.sample_type}/*/bins/DASTool/_DASTool_bins/*.fa {output}
        """

rule gtdbtk:
    input:
        bins = rules.dastool.output.das_bins_folder,
        refs = "/geomicro/data2/kiledal/references/gtdbtk/release202"
    output: directory("data/omics/{sample_type}/{sample}/bins/gtdbtk")
    conda: "config/conda_yaml/gtdbtk.yaml"
    resources: cpus=1, mem_mb=500000, time_min=2880, mem_gb = 500
    shell:
        """
        GTDBTK_DATA_PATH={input.refs}

        gtdbtk classify_wf --extension fa --genome_dir {input.bins} --out_dir {output} --cpus {resources.cpus}
        """

rule binning:
    input: 
        #"data/omics/metagenome_bins",
        #expand("data/omics/metagenomes/{sample}/bins/reassembly/{bin}_reassembled_contigs.fasta", sample = metaG_samples, bin = glob_wildcards("data/omics/metagenomes/{sample}/bins/reassembly/{bin}_reassembled_contigs.fasta").bin),
        "data/omics/metagenomes/0ae7941e0cc52de7e4913cf5defec020/bins/reassembly/0ae7941e0cc52de7e4913cf5defec020_concoct_bin.16_reassembled_contigs.fasta",
        expand("data/omics/metagenomes/{sample}/bins/coverage.tsv", sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/bins/checkm.txt", sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/bins/gtdbtk", sample = metaG_samples)


# rule gtdbtk_all:
#     input:
#         bins = rules.gather_bin.output,
#         refs = "/geomicro/data2/kiledal/references/gtdbtk/release202"
#     output: directory("data/gtdbtk")
#     conda: "code/gtdbtk.yaml"
#     resources: cpus=32, mem_mb=250000, time_min=2880, mem_gb = 250
#     shell:
#         """
#         GTDBTK_DATA_PATH={input.refs}

#         gtdbtk classify_wf --extension fa --genome_dir {input.bins} --out_dir {output} --cpus {resources.cpus} --pplacer_cpus 1
#         """

rule run_sourmash: 
    input: expand("data/omics/metagenomes/{sample}/sourmash/{sample}_gather_gtdbrs207_reps.csv", sample=metaG_samples)

rule run_sourmash_jgi: 
    input: expand("data/omics/metagenomes/{sample}/sourmash/{sample}_gather_gtdbrs207_reps.csv", sample=jgi_samples)

rule run_sourmash_glerl: 
    input: expand("data/omics/metagenomes/{sample}/sourmash/{sample}_gather_gtdbrs207_reps.csv", sample=glerl_samples)

rule run_sourmash_transect: 
    input: expand("data/omics/metagenomes/{sample}/sourmash/{sample}_gather_gtdbrs207_reps.csv", sample=transect_samples)


rule run_sourmash_Microcystis: 
    input: expand("data/omics/metagenomes/{sample}/sourmash/{sample}_gather_Microcystis.csv", sample=metaG_samples)





#### For testing on only one sample ####
#metaG_samples = "c39841b318d0487eda9e0134e5c06381"
#metaG_samples = "coassembly"
########################################


# rule calc_contig_coverage:
#     input: 
#         expand("data/omics/metagenomes/{sample}/reads/.linked_w_sample_name", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.renamed.fa", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
#         expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = "2022_geomicro_JGI_CSP")

current_project = "set_36" # Other projects used recetly-- 2021_ESP, 2022_geomicro_JGI_CSP, PRJNA702522, WLE_transects_2022, GLERL_USGS_2016_2020
metaG_samples = os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines()
rule calc_contig_coverage_proj1:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/.linked_{dir}_w_sample_name", sample = metaG_samples, project = current_project, dir = ["fwd", "rev"]),
        expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = current_project)

current_project = "set_41" # Other projects used recetly-- 2021_ESP, 2022_geomicro_JGI_CSP, PRJNA702522, WLE_transects_2022, GLERL_USGS_2016_2020
#metaG_samples = [item for item in os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines() if not re.match("^samp_4", item) and item not in ["coassembly", "samp_4418"]]
metaG_samples = [item for item in os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines() if item not in ["coassembly", "samp_4418"]]
rule calc_contig_coverage_proj2:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/.linked_{dir}_w_sample_name", sample = metaG_samples, project = current_project, dir = ["fwd", "rev"]),
        #expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = current_project),
        #expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/bins_for_drep/.bins_linked", sample = metaG_samples, project = current_project)

current_project = "2022_geomicro_JGI_CSP" # Other projects used recetly-- 2021_ESP, 2022_geomicro_JGI_CSP, PRJNA702522, WLE_transects_2022, GLERL_USGS_2016_2020
#metaG_samples = os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines()
#metaG_samples = list(filter(lambda x: x.startswith('samp_'), metaG_samples))
metaG_samples = ['samp_4304', 'samp_4305', 'samp_4306', 'samp_4333']
metaG_samples = ['samp_4306']
metaG_samples = ['coassembly_10']
rule calc_contig_coverage_proj3:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/.linked_{dir}_w_sample_name", sample = metaG_samples, project = current_project, dir = ["fwd", "rev"]),
        expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = current_project)






current_project = "set_57" # Other projects used recetly-- 2021_ESP, 2022_geomicro_JGI_CSP, PRJNA702522, WLE_transects_2022, GLERL_USGS_2016_2020
metaG_samples = os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines()
rule calc_contig_coverage_proj4:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/.linked_{dir}_w_sample_name", sample = metaG_samples, project = current_project, dir = ["fwd", "rev"]),
        expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = current_project)

current_project = "2022_doli_genome_binning" # Other projects used recetly-- 2021_ESP, 2022_geomicro_JGI_CSP, PRJNA702522, WLE_transects_2022, GLERL_USGS_2016_2020
metaG_samples = os.popen("ls data/projects/" + current_project + "/metagenomes/").read().splitlines()
metaG_samples = ['samp_4431']
rule calc_contig_coverage_proj5:
    input: 
        expand("data/omics/metagenomes/{sample}/reads/.linked_{dir}_w_sample_name", sample = metaG_samples, project = current_project, dir = ["fwd", "rev"]),
        expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB", sample = metaG_samples, project = current_project),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = current_project)

def get_project_inputs(projects):
    inputs = []
    if projects is not None:
        for project in projects:
            binning_samples = subprocess.Popen(f"ls -d data/projects/{project}/metagenomes/samp_* | grep -o 'samp_.*'", shell=True, stdout=subprocess.PIPE).stdout.read().decode().splitlines()
            for sample in metaG_samples:
                sample_inputs = [
                    "data/omics/metagenomes/{sample}/reads/.linked_fwd_w_sample_name".format(sample=sample),
                    "data/omics/metagenomes/{sample}/reads/.linked_rev_w_sample_name".format(sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/semibin".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/VAMB".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/.drep_done".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB".format(project=project, sample=sample),
                    "data/projects/{project}/metagenomes/{sample}/bins/.done_gunc".format(project=project, sample=sample),
                ]
                inputs.extend(sample_inputs)
    return inputs

rule bin_projects: 
    input: get_project_inputs(config["projects"])


rule run_checkm_new_per_sample:
    input: expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample =metaG_samples, project = "2022_geomicro_JGI_CSP")


rule gunc_and_drep:
    input: 
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc", sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP")


rule bin_coassembly:
    input: 
        expand("data/projects/{project}/metagenomes/{sample}/bins/contig_coverage.tsv", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/CONCOCT/cut_contigs_10K.fa", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.renamed.fa", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/semibin", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/METABAT2/.done/", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/maxbin/.done", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/VAMB", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/metadecoder/.done", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/all_raw_bins/checkm.txt", sample = "coassembly", project = "2022_geomicro_JGI_CSP"),
        #expand("data/omics/metagenomes/{sample}/bins/das_tool/.done", sample = "coassembly"),
        #expand("data/omics/metagenomes/{sample}/bins/.drep_done", sample = "coassembly")


rule run_contig_map:
    input: 
        #expand("data/projects/{project}/metagenomes/{sample}/bins/bam", sample = "coassembly", project = "2022_geomicro_JGI_CSP")
        expand(config["binning_bam_dir"], sample = "coassembly", project = "2022_geomicro_JGI_CSP", sample_type = "metagenomes")

rule run_semibin:
    input: expand("data/projects/{project}/metagenomes/{sample}/bins/semibin/.done", sample = metaG_samples, project = "2022_geomicro_JGI_CSP")

rule run_drep_sep:
    input:
        expand("data/projects/{project}/metagenomes/{sample}/bins/.drep_done",sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/das_tool/.done",sample = metaG_samples, project = "2022_geomicro_JGI_CSP"),
        expand("data/projects/{project}/metagenomes/{sample}/bins/.done_GTDB",sample = metaG_samples, project = "2022_geomicro_JGI_CSP")
        #expand("data/projects/{project}/metagenomes/{sample}/bins/.done_gunc",sample = metaG_samples)

rule run_kofam_scan_bins:
    input:
        expand("data/omics/metagenomes/coassembly/bins/kofamscan/{bin}_kofam_results.txt", bin = glob_wildcards("data/omics/metagenomes/coassembly/bins/drep_ALL_SAMPLES/dereplicated_genomes/{BIN,[^/]+}.fa").BIN)

rule run_prodigal_mags_DREP:
    input: expand("data/omics/metagenomes/coassembly/bins/drep_ALL_SAMPLES/dereplicated_genomes/prodigal/{bin}.faa", bin = glob_wildcards("data/omics/metagenomes/coassembly/bins/drep_ALL_SAMPLES/dereplicated_genomes/{BIN,[^/]+}.fa").BIN)


bakta_df = pd.read_table('data/projects/2022_geomicro_JGI_CSP/metagenomes/bakta_dirs.tsv').set_index("bakta_dir", drop=False)
bakta_genome_names = list(bakta_df['bakta_dir'])

rule run_bakta:
    input:
        bakta_genome_names

# def mags_to_annotate(wildcards):
#     checkpoint_output = checkpoints.dastool_new.get(**wildcards).output["das_done"]
#     PROJECTS, SAMPLES, SAMPLES2, GENOMES = glob_wildcards("data/projects/{project}/metagenomes/{sample}/bins/das_tool/output/{sample2}_DASTool_bins/{genome}.fa")
#     file_names = expand("data/projects/{project}/metagenomes/{sample}/bins/bakta/{genome}", zip, project = PROJECTS, sample = SAMPLES, genome = GENOMES)
#     return file_names

PROJECTS, SAMPLES, SAMPLES2, GENOMES = glob_wildcards("data/projects/{project}/metagenomes/{sample}/bins/das_tool/output/{sample2}_DASTool_bins/{genome}.fa")


rule run_bakta_dynamic:
    input:
        expand("data/projects/{project}/metagenomes/{sample}/bins/bakta/{genome}", zip, project = PROJECTS, sample = SAMPLES, genome = GENOMES)


# def aggregate_decompress_plass(wildcards):
#     checkpoint_output = checkpoints.decompress_plass.get(**wildcards).output[0]    
#     file_names = expand("outputs/cd-hit95/{mag}.cdhit95.faa", 
#                         mag = glob_wildcards(os.path.join(checkpoint_output, "{mag}.fa.cdbg_ids.reads.hardtrim.fa.gz.plass.cdhit.fa.clean.cut.dup")).mag)
#     return file_names

antismash_df = pd.read_table('data/projects/2022_geomicro_JGI_CSP/metagenomes/antismash_dirs.tsv').set_index("antismash_dir", drop=False)
antismash_df_names = list(antismash_df['antismash_dir'])


rule run_antismash:
    input:
        antismash_df_names

rule annotate_bins:
    input:
        #"data/omics/metagenomes/coassembly/bins/drep_ALL_SAMPLES/dereplicated_genomes/traitar/.done",
        expand("data/omics/metagenomes/coassembly/bins/kofamscan/{bin}_kofam_results.txt", bin = glob_wildcards("data/omics/metagenomes/coassembly/bins/drep_ALL_SAMPLES/dereplicated_genomes/{BIN,[^/]+}.fa").BIN),
        antismash_df_names

rule run_bakta_assembly:
    input: expand("data/omics/metagenomes/{sample}/bakta_assembly", sample = jgi_samples)

rule run_antismash_assembly:
    input: expand("data/omics/metagenomes/{sample}/antismash_assembly", sample = jgi_samples)

    rule run_toxin_gene_read_mapping:
    input: 
        #expand("data/omics/metagenomes/{sample}/ref_read_mapping/toxin-genes_mapped.bam", sample = qcd_samples),
        expand("data/omics/metagenomes/{sample}/ref_read_mapping/toxin-genes_pileup.txt", sample = qcd_samples),
        expand("data/omics/metatranscriptomes/{sample}/ref_read_mapping/toxin-genes_pileup.txt", sample = qcd_transcript_samples)


kofamscan_df = open('../projects/2023_glerl_usgs_metagenomes/data/kofamscan_bin_list').read().splitlines()


rule run_kofam_glerl:
    input:
        kofamscan_df

        rule JGI_SAMPLES_kraken_summarize_fastp:
        input:
            script = "code/merge_bracken.R",
            kraken_results = expand("data/omics/metagenomes/{sample}/kraken_fastp/{database}_{sample}_bracken.txt", database = ["refseq","gtdb"], sample = glob_wildcards("import/staging/jgi_2022/all_sample_filtered_reads/{sample}_interleaved.fastq.gz").sample),
            combined_tax_info = "data/reference/kraken_tax_info_merged.tsv"
        output:
            counts = "data/sample_data/JGI_bracken_counts.tsv",
            rel_abund = "data/sample_data/JGI_bracken_rel_abund.tsv"
        resources: cpus=1, mem_mb=5000, time_min=60
        container: "docker://eandersk/r_microbiome"
        shell:
            """
            ./{input.script} --taxonomy={input.combined_tax_info} --counts-out={output.counts} --rel-out={output.rel_abund}
            """

rule deinterleave_jgi:
    input:
        expand("data/omics/metagenomes/{sample}/reads/decon_fwd_reads_fastp.fastq.gz", sample = glob_wildcards("import/staging/jgi_2022/all_sample_filtered_reads/{sample}_interleaved.fastq.gz").sample)


rule run_fastqc_fastp:
    input: expand("data/omics/metagenomes/{sample}/reads/fastqc_fastp/.done", sample = metaG_samples),
        expand("data/omics/metagenomes/{sample}/reads/qc/multiqc",sample = metaG_samples)


# rule remove_spike_ins_fastp:
#     input:
#         spike_ins = rules.get_contaminants.output.spike_ins,
#         trimmed_fwd = rules.fastp.output.fwd_reads,
#         trimmed_rev = rules.fastp.output.rev_reads
#     output:
#         phix_rm_fwd = temp("data/omics/metagenomes/{sample}/reads/phix_fwd_reads_fastp.fastq.gz"),
#         phix_rm_rev = temp("data/omics/metagenomes/{sample}/reads/phix_rev_reads_fastp.fastq.gz")
#     conda: "config/conda_yaml/main.yaml"
#     log: "logs/remove_spike_ins/{sample}_fastp.log"
#     params:
#         bbmap_index_path = "data/reference/contaminants"
#     benchmark:
#         "benchmarks/remove_spike_ins_fastp/{sample}.txt"
#     resources: cpus = 24, mem_mb = lambda wildcards, attempt: attempt * 150000, time_min = 2880
#     shell:
#         """        
#         bbmap_mem=$(echo "scale=-1; ({resources.mem_mb}*0.8)/1" | bc)
       
#         echo "Job memory= {resources.mem_mb}, bbmap allocated memory=$bbmap_mem because it is greedy"

#         echo "\n\n***Removing spike-in***\n\n" >> {log}
        
#         bbduk.sh -Xmx${{bbmap_mem}}m -eoom \
#             in1={input.trimmed_fwd} \
#             in2={input.trimmed_rev} \
#             outu1={output.phix_rm_fwd} \
#             outu2={output.phix_rm_rev} \
#             t={resources.cpus} k=31 hdist=1 \
#             ref={input.spike_ins} \
#             path={params.bbmap_index_path} \
#             1>>{log} 2>&1

#         echo "\n\n*** DONE ***\n\n" >> {log}
#         """


# Run the Bash commands and capture the output
output = subprocess.check_output(['bash', '-c', find_mmseq_reports]).decode('utf-8')
mmseq_report_samples = [sample.strip() for sample in output.split()]


rule fortify_unrefLCA:
    input: 
        #expand("data/omics/metagenomes/{sample}/{sample}_report_w_full_lineage", sample = glob_wildcards("data/omics/metagenomes/{samp}/{samp2}_report").samp),
        expand("data/omics/metagenomes/{sample}/{sample}_report_w_full_lineage", sample = mmseq_report_samples),
        #expand("data/omics/metagenomes/{sample}/{sample}_report", sample = glob_wildcards("data/omics/metagenomes/{samp}/{samp2}_report").samp)
